# IRL-Fall-2022
Codes from Illinois Risk Lab Fall 2022 semester

## Explainable AI and Algorithm Bias

This project focuses on finding explainable AI and interpretable ML algorithms. Nowadays advanced AI algorihms are usually treated as black-box and difficult for interpretation. One of the ways researchers solving Algorithm Bias is through Explainable AI (XAI) and Interpretable AI where the process of decision-making must become transparent and easily understandable by humans.

# SIMTree Case Study
This case study focused on comparison of two interpretable ML methods: SIMTree and Hybrid Tree-based method. SIMTree is proposed by Agus, Zebin, and Aijun (2021). It is an intrinsically interpretable model with relatively high accuracy. This study compares SIMTree Model with the Hybrid Tree-based Method proposed by Professor Quan using the Boston Housing dataset.


# EGBM Case Study
This case study focused on comparision of two interpretable ML methods: Ensemble of Gradient Boosting Machine and traditional Gradient Boosting Machine. Ensemble of gradient boosting machines (EGBM) is proposed by Konstantinov and Utkin (2021) that provides an improved interpretation method of traditional gradient boosting machines. This study compares EGBM method with the traditional GBM using LightGBM package in python. 
